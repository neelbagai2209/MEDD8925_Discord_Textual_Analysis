{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9343f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b338b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_word(term):\n",
    "    \"\"\"Check if a term is a single word with allowed characters.\"\"\"\n",
    "    return re.fullmatch(r\"[a-zA-Z0-9\\-]+\", term) is not None\n",
    "\n",
    "def extract_sitemap_urls(index_file_path, max_sitemaps=1520):\n",
    "    \"\"\"Extract all .gz sitemap URLs from the main sitemap index.\"\"\"\n",
    "    tree = ET.parse(index_file_path)\n",
    "    root = tree.getroot()\n",
    "    ns = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "    urls = [loc.text for loc in root.findall(\"ns:sitemap/ns:loc\", ns)]\n",
    "    return urls[:max_sitemaps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d87b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_terms_from_sitemap(sitemap_url):\n",
    "    \"\"\"Download and extract one-word slang terms from a sitemap .gz file.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(sitemap_url, timeout=20)\n",
    "        with gzip.GzipFile(fileobj=BytesIO(response.content)) as f:\n",
    "            tree = ET.parse(f)\n",
    "            root = tree.getroot()\n",
    "            ns = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "            terms = []\n",
    "            for url_elem in root.findall(\"ns:url\", ns):\n",
    "                loc = url_elem.find(\"ns:loc\", ns).text\n",
    "                if \"define.php?term=\" in loc:\n",
    "                    term = loc.split(\"term=\")[-1].replace(\"+\", \" \").strip()\n",
    "                    if is_one_word(term):\n",
    "                        terms.append(term.lower())\n",
    "            return terms\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {sitemap_url}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef24f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Found 1520 sitemap files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a43b4c663b9402e852f2d6ce2c4697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîÑ Processing sitemaps:   0%|          | 0/1520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extracted 1,636,457 unique one-word slang terms.\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "SITEMAP_INDEX_FILE = r\"C:\\Users\\neelb\\Desktop\\MEDD8925 - Analyzing Data Quantitatively\\Final Project\\urbandict_sitemap_gz.xml\"\n",
    "MAX_SITEMAPS = 1520  # You can reduce this temporarily for testing\n",
    "OUTPUT_FILE = \"urban_dictionary_one_word_slangs.txt\"\n",
    "\n",
    "# === MAIN PROCESS ===\n",
    "\n",
    "sitemap_urls = extract_sitemap_urls(SITEMAP_INDEX_FILE, max_sitemaps=MAX_SITEMAPS)\n",
    "print(f\"üì¶ Found {len(sitemap_urls)} sitemap files.\")\n",
    "\n",
    "all_terms = set()\n",
    "\n",
    "for sitemap_url in tqdm(sitemap_urls, desc=\"üîÑ Processing sitemaps\"):\n",
    "    terms = extract_terms_from_sitemap(sitemap_url)\n",
    "    all_terms.update(terms)\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted {len(all_terms):,} unique one-word slang terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb04ebc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Filtered terms: 1,540,197 remain after removing non-alphabetic ones.\n"
     ]
    }
   ],
   "source": [
    "# üí° Filter out any terms that contain non-alphabetic characters\n",
    "filtered_terms = {term for term in all_terms if term.isalpha()}\n",
    "\n",
    "print(f\"üßπ Filtered terms: {len(filtered_terms):,} remain after removing non-alphabetic ones.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89112571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved one-word slang terms to: C:\\Users\\neelb\\Desktop\\MEDD8925 - Analyzing Data Quantitatively\\Final Project\\urban_dictionary_one_word_slangs.txt\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    for term in sorted(filtered_terms):\n",
    "        f.write(term + \"\\n\")\n",
    "\n",
    "print(f\"üíæ Saved one-word slang terms to: {os.path.abspath(OUTPUT_FILE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2cc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
